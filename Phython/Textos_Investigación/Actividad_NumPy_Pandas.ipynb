{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1dcc3c0",
   "metadata": {},
   "source": [
    "\n",
    "# Resumen y aplicación práctica: NumPy (ndarray, broadcasting y memoria mapeada) y pandas  \n",
    "**Autor:** *Romel Carlof IZAGUIRRE BARBARAN*  \n",
    "**Fecha:** 2025-09-17\n",
    "\n",
    "---\n",
    "\n",
    "Este cuaderno recopila y comenta dos artículos fundacionales para el análisis numérico y de datos en Python:\n",
    "\n",
    "1. **Van der Walt, Colbert & Varoquaux (2011)** — *The NumPy array: A structure for efficient numerical computation*.\n",
    "2. **McKinney (2010)** — *Data Structures for Statistical Computing in Python*.\n",
    "\n",
    "A partir de ambas referencias se muestran **resúmenes críticos** y **ejemplos reproducibles** con **NumPy** y **pandas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1572ab",
   "metadata": {},
   "source": [
    "\n",
    "## Objetivos y metodología\n",
    "\n",
    "**Objetivos**\n",
    "- Sintetizar los aportes clave de *Van der Walt et al. (2011)* sobre `ndarray`, broadcasting y memoria mapeada.\n",
    "- Sintetizar los aportes clave de *McKinney (2010)* sobre las estructuras de datos de `pandas` y su papel en la computación estadística.\n",
    "- Ilustrar con **código**: (i) reglas, restricciones y casos de uso de **broadcasting** y (ii) **memoria mapeada** con `numpy.memmap`.  \n",
    "- Presentar un **miniejemplo** con `pandas` que evidencie indexación, alineamiento y operaciones tipo *groupby*.\n",
    "\n",
    "**Metodología**\n",
    "- Lectura de los artículos y elaboración de un **resumen crítico**.\n",
    "- Desarrollo de **experimentos breves** con `NumPy` y `pandas` para consolidar lo expuesto.\n",
    "- Redacción en celdas Markdown y **código comentado** siguiendo las buenas prácticas del cuaderno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e4f74",
   "metadata": {},
   "source": [
    "\n",
    "## Artículo 1 — NumPy: ndarray, broadcasting y memoria mapeada\n",
    "\n",
    "**Referencia resumida**  \n",
    "Van der Walt, S., Colbert, S. C., & Varoquaux, G. (2011). *The NumPy array: A structure for efficient numerical computation*. **Computing in Science & Engineering, 13(2)**, 22-30.\n",
    "\n",
    "**Ideas clave**\n",
    "- `ndarray` provee **almacenamiento contiguo** (o *strided*) y un **sistema de vistas** sin copias, facilitando operaciones vectorizadas de alto rendimiento.\n",
    "- El **broadcasting** permite operaciones aritméticas entre arrays de distinta forma cuando sus **dimensiones son compatibles** (regla de alinear desde la derecha y dimension 1 extensible).\n",
    "- `numpy.memmap` habilita el trabajo con **datos más grandes que la memoria RAM** mediante archivos mapeados, útil para cargas que no caben en memoria a costa de latencias I/O.\n",
    "- La **vectorización** y el uso de **uFuncs** minimizan bucles en Python, mejorando el rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6959142",
   "metadata": {},
   "source": [
    "\n",
    "### Pregunta 1 — Broadcasting: explicación extendida, restricciones y ejemplos\n",
    "\n",
    "**Reglas de compatibilidad (resumen práctico):**\n",
    "1. Se comparan las formas **desde la última dimensión hacia la primera**.\n",
    "2. Las dimensiones son compatibles si son **iguales** o si alguna es **1**.\n",
    "3. Si alguna dimensión no cumple (ni igual ni 1), la operación **falla** con `ValueError`.\n",
    "\n",
    "**Limitaciones y consideraciones:**\n",
    "- El broadcasting **no crea copias** por sí mismo, pero la operación resultante puede materializar un array temporal grande (posible **alto consumo de memoria**).\n",
    "- Operaciones que expanden implícitamente dimensiones de tamaño 1 a tamaños grandes pueden **ocupar memoria** si se materializan resultados grandes.\n",
    "- No todas las funciones aceptan argumentos broadcastables en el mismo sentido; conviene **leer la docstring** y **probar dimensiones**.\n",
    "- Para datos muy grandes, preferir **operaciones en bloque** (chunking) o **out=** en uFuncs cuando corresponda.\n",
    "\n",
    "A continuación se muestran ejemplos ilustrativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ejemplo A: Compatibles (3, 1) con (1, 4) -> resultado (3, 4)\n",
    "A = np.arange(3).reshape(3, 1)       # [[0],[1],[2]]\n",
    "B = np.arange(4).reshape(1, 4)       # [[0,1,2,3]]\n",
    "C = A + B\n",
    "print(\"A.shape:\", A.shape, \"B.shape:\", B.shape, \"C.shape:\", C.shape)\n",
    "print(C)\n",
    "\n",
    "# Ejemplo B: Incompatibles -> ValueError\n",
    "try:\n",
    "    X = np.zeros((2, 3))\n",
    "    Y = np.ones((4, 1))\n",
    "    Z = X + Y\n",
    "except ValueError as e:\n",
    "    print(\"\\nBroadcasting incompatible:\", e)\n",
    "\n",
    "# Ejemplo C: Uso de np.newaxis / None para alinear dimensiones\n",
    "v = np.array([10, 20, 30])      # shape (3,)\n",
    "w = np.array([1, 2, 3, 4])      # shape (4,)\n",
    "\n",
    "# Convertimos a (3,1) y (1,4) para obtener una tabla 3x4\n",
    "tabla = v[:, None] * w[None, :]\n",
    "print(\"\\nTabla v*w shape:\", tabla.shape)\n",
    "print(tabla)\n",
    "\n",
    "# Ejemplo D: ufunc con out= para evitar temporales innecesarios\n",
    "out = np.empty_like(tabla)\n",
    "np.multiply(v[:, None], w[None, :], out=out)\n",
    "print(\"\\nUso de out=, coincide con 'tabla':\", np.allclose(out, tabla))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b24ef6",
   "metadata": {},
   "source": [
    "\n",
    "### Pregunta 2 — Memoria mapeada (`numpy.memmap`): eficacia y rendimiento\n",
    "\n",
    "**Idea:** `memmap` permite tratar un archivo en disco como si fuera un array. Ventaja clave: **trabajar con datos que exceden la RAM**, cargar **trozos** sin leer todo a memoria y **persistir** parcialmente.\n",
    "\n",
    "**Advertencias de rendimiento:**\n",
    "- Para tamaños **pequeños** o acceso **aleatorio** frecuente, `memmap` puede ser **más lento** que arrays en RAM por la latencia de disco.\n",
    "- Para flujos **secuenciales** grandes o procesamiento en **bloques**, `memmap` ayuda a no agotar memoria y puede ser competitivo.\n",
    "- Usar `dtype` compactos (`float32`, `int32`) y **lectura por chunks** ayuda.\n",
    "\n",
    "**Demostración breve** (no concluyente): se compara el tiempo de escritura/lectura secuencial de un array moderado con `memmap` vs. un `.npy` convencional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ff39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os, time\n",
    "\n",
    "# Configuración de tamaño moderado para esta demo (ajustable)\n",
    "shape = (5000, 200)       # ~1e6 elementos\n",
    "dtype = np.float32        # ~4 MB por millón de elementos\n",
    "arr = np.random.rand(*shape).astype(dtype)\n",
    "\n",
    "# Rutas de archivos en el entorno actual\n",
    "memmap_path = \"demo_memmap.dat\"\n",
    "npy_path = \"demo_array.npy\"\n",
    "\n",
    "# ---- Escritura con memmap (secuencial) ----\n",
    "t0 = time.perf_counter()\n",
    "mm = np.memmap(memmap_path, dtype=dtype, mode=\"w+\", shape=shape)\n",
    "mm[:] = arr[:]      # escritura secuencial\n",
    "mm.flush()\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "# ---- Lectura con memmap (secuencial) ----\n",
    "mm_read = np.memmap(memmap_path, dtype=dtype, mode=\"r\", shape=shape)\n",
    "s1 = time.perf_counter()\n",
    "_ = mm_read.sum()\n",
    "s2 = time.perf_counter()\n",
    "\n",
    "# ---- Guardar / cargar con .npy convencional ----\n",
    "u0 = time.perf_counter()\n",
    "np.save(npy_path, arr)\n",
    "u1 = time.perf_counter()\n",
    "v0 = time.perf_counter()\n",
    "arr2 = np.load(npy_path, mmap_mode=None)  # carga completa en RAM\n",
    "_ = arr2.sum()\n",
    "v1 = time.perf_counter()\n",
    "\n",
    "print(f\"memmap write: {t1 - t0:.4f}s | memmap read&sum: {s2 - s1:.4f}s\")\n",
    "print(f\"npy save:     {u1 - u0:.4f}s | npy load&sum:   {v1 - v0:.4f}s\")\n",
    "\n",
    "# Limpieza opcional de archivos (descomente si desea borrar al terminar)\n",
    "# os.remove(memmap_path); os.remove(npy_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784337cf",
   "metadata": {},
   "source": [
    "\n",
    "## Artículo 2 — pandas: estructuras de datos para computación estadística\n",
    "\n",
    "**Referencia resumida**  \n",
    "McKinney, W. (2010). *Data Structures for Statistical Computing in Python*. **Proceedings of the 9th Python in Science Conference**, 56-61.\n",
    "\n",
    "**Ideas clave**\n",
    "- `Series` y `DataFrame` aportan **etiquetado de ejes (índices)**, **alineamiento** automático por etiquetas y **operaciones vectorizadas** de alto nivel.\n",
    "- Soporte para **lectura/escritura** de múltiples formatos, **reindexación**, **reshaping** (pivot/melt) y **groupby** (split-apply-combine).\n",
    "- Integración con **NumPy** y ecosistema científico de Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613c1a7",
   "metadata": {},
   "source": [
    "\n",
    "### Pregunta 3 — Estado actual: Python vs R vs SQL vs Others (discusión breve)\n",
    "\n",
    "- **Python (pandas, NumPy)**: gran ecosistema (scikit-learn, PyTorch, JAX), uso general, prototipado ágil. Ventajas en **integración** (APIs, web, ML). Retos: manejo de **big data** en un solo nodo; opciones modernas incluyen **Polars** y **DuckDB** para acelerar consultas tabulares locales.\n",
    "- **R (tidyverse, data.table)**: ergonomía estadística, **visualización** excelente (ggplot2) y comunidad académica fuerte. *data.table* destaca por rendimiento en tablas grandes; tidyverse ofrece una **sintaxis declarativa** muy clara.\n",
    "- **SQL**: estándar universal para datos tabulares y **sistemas transaccionales/analíticos**; en la práctica convive con Python/R. Herramientas como **DuckDB** hacen SQL **embebido** y eficiente en local; en la nube, motores tipo **BigQuery**/**Snowflake**.\n",
    "- **Otros**: **Julia** (alto rendimiento numérico, sintaxis amigable), **Apache Arrow** (intercambio columnar de datos), **Spark** (distribuido).\n",
    "\n",
    "**Conclusión breve:** La elección depende del **contexto**. Para análisis en un solo equipo, **pandas/Polars + DuckDB** y/o **R (data.table/tidyverse)** son opciones sólidas. Para ML, Python domina; para consultas declarativas y gobernanza de datos, **SQL** es indispensable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ff080",
   "metadata": {},
   "source": [
    "\n",
    "### Ejemplo con `pandas`: alineamiento, groupby y pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset sintético\n",
    "ventas = pd.DataFrame({\n",
    "    \"fecha\": pd.to_datetime([\"2025-01-05\",\"2025-01-05\",\"2025-01-06\",\"2025-01-06\",\"2025-01-06\"]),\n",
    "    \"tienda\": [\"A\",\"B\",\"A\",\"A\",\"B\"],\n",
    "    \"producto\": [\"X\",\"X\",\"X\",\"Y\",\"Y\"],\n",
    "    \"unidades\": [10, 12, 8, 5, 7],\n",
    "    \"precio\": [2.5, 2.5, 2.5, 5.0, 5.0]\n",
    "})\n",
    "\n",
    "# Ingreso por fila\n",
    "ventas[\"ingreso\"] = ventas[\"unidades\"] * ventas[\"precio\"]\n",
    "\n",
    "# GroupBy: ingreso total por tienda y producto\n",
    "resumen = (\n",
    "    ventas\n",
    "    .groupby([\"tienda\", \"producto\"], as_index=False)[\"ingreso\"]\n",
    "    .sum()\n",
    "    .sort_values([\"tienda\",\"producto\"])\n",
    ")\n",
    "\n",
    "print(\"Ventas:\n",
    "\", ventas, \"\\n\")\n",
    "print(\"Resumen por tienda y producto:\n",
    "\", resumen, \"\\n\")\n",
    "\n",
    "# Pivot: tabla tienda x producto (ingreso)\n",
    "pivot = ventas.pivot_table(index=\"tienda\", columns=\"producto\", values=\"ingreso\", aggfunc=\"sum\", fill_value=0.0)\n",
    "print(\"Pivot tienda x producto (ingreso):\\n\", pivot, \"\\n\")\n",
    "\n",
    "# Alineamiento: suma de Series con índices distintos\n",
    "s1 = pd.Series({\"A\": 100.0, \"B\": 200.0})\n",
    "s2 = pd.Series({\"A\": 10.0, \"C\": 30.0})\n",
    "print(\"Alineamiento por índice en suma s1 + s2:\")\n",
    "print(s1 + s2)  # 'B' y 'C' no coinciden, aparecen NaN donde falta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8f367",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusiones\n",
    "- `ndarray` es la piedra angular del cómputo numérico en Python; **broadcasting** potencia expresividad y velocidad, pero requiere vigilar **compatibilidad de formas** y **materialización de temporales**.\n",
    "- `memmap` es útil cuando los datos **no caben en RAM** o se requiere **persistencia** incremental; su rendimiento depende de patrones de acceso y del hardware de almacenamiento.\n",
    "- `pandas` aporta estructuras etiquetadas y operaciones de alto nivel que **agilizan** el análisis estadístico/tabular; conviene combinarlo con herramientas modernas (p. ej., **DuckDB/Polars**) según el tamaño/forma de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7664aa81",
   "metadata": {},
   "source": [
    "\n",
    "## Referencias\n",
    "\n",
    "- Van der Walt, S., Colbert, S. C., & Varoquaux, G. (2011). The NumPy array: A structure for efficient numerical computation. *Computing in Science & Engineering, 13(2)*, 22–30. Disponible en: https://www.researchgate.net/publication/224223550_The_NumPy_Array_A_Structure_for_Efficient_Numerical_Computation\n",
    "\n",
    "- McKinney, W. (2010). Data Structures for Statistical Computing in Python. *Proceedings of the 9th Python in Science Conference*, 56–61. Disponible en: https://www.researchgate.net/publication/265001241_Data_Structures_for_Statistical_Computing_in_Python\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
