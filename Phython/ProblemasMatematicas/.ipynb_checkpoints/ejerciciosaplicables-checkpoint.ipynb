{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0d607f",
   "metadata": {},
   "source": [
    "# Ejercicios evaluables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6184e25",
   "metadata": {},
   "source": [
    "# 1. Tal y como ya hemos visto en clase, la variedad de herramientas proporcionadas por el\n",
    "´algebra lineal son cruciales para desarrollar y fundamentar las bases de una variedad de\n",
    "t´ecnicas relacionadas con el aprendizaje autom´atico. Con ella, podemos describir el proceso\n",
    "de propagaci´on hacia adelante en una red neuronal, identificar m´ınimos locales en funciones\n",
    "multivariables (crucial para el proceso de retropropagaci´on) o la descripci´on y empleo de\n",
    "m´etodos de reducci´on de la dimensionalidad, como el an´alisis de componentes principales\n",
    "(PCA), entre muchas otras aplicaciones.\n",
    "Cuando trabajamos en la pr´actica dentro de este ´ambito, la cantidad de datos que manejamos\n",
    "puede ser muy grande, por lo que es especialmente importante emplear algoritmos eficientes\n",
    "y optimizados para reducir el coste computacional en la medida de lo posible. Por todo ello,\n",
    "el objetivo de este ejercicio es el de ilustrar las diferentes alternativas que pueden existir\n",
    "para realizar un proceso relacionado con el ´algebra lineal y el impacto que puede tener cada\n",
    "variante en t´erminos del coste computacional del mismo. En este caso en particular, y a modo\n",
    "de ilustraci´on, nos centraremos en el c´alculo del determinante de una matriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570e410",
   "metadata": {},
   "source": [
    "# a) [1 punto] Implementa una funci´on, determinante recursivo, que obtenga el determinante de una matriz cuadrada utilizando la definici´on recursiva de Laplace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7fc8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante: 1\n"
     ]
    }
   ],
   "source": [
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "\n",
    "    # Caso base 1x1\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "\n",
    "    # Caso base 2x2\n",
    "    if n == 2:\n",
    "        return mat[0][0] * mat[1][1] - mat[0][1] * mat[1][0]\n",
    "\n",
    "    # Recursión para n > 2\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        # Crear el menor\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += ((-1) ** j) * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Ejemplo de uso\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [0, 1, 4],\n",
    "    [5, 6, 0]\n",
    "]\n",
    "\n",
    "print(\"Determinante:\", determinante_recursivo(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc9366",
   "metadata": {},
   "source": [
    "# b).  [0.5 puntos] Si A es una matriz cuadrada n×n y triangular (superior o inferior, es decir,\n",
    "# con entradas nulas por debajo o por encima de la diagonal, respectivamente), ¿existe\n",
    "# alguna forma de calcular de forma directa y sencilla su determinante? Justif´ıquese la\n",
    "# respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930e1d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante (matriz triangular): 36\n"
     ]
    }
   ],
   "source": [
    "def determinante_triangular(mat):\n",
    "    \"\"\"\n",
    "    Calcula el determinante de una matriz triangular (superior o inferior).\n",
    "    Se asume que la matriz es cuadrada y triangular.\n",
    "    \"\"\"\n",
    "    n = len(mat)\n",
    "    det = 1\n",
    "    for i in range(n):\n",
    "        det *= mat[i][i]\n",
    "    return det\n",
    "\n",
    "# Ejemplo: matriz triangular superior\n",
    "A = [\n",
    "    [3, 5, 1],\n",
    "    [0, 2, 4],\n",
    "    [0, 0, 6]\n",
    "]\n",
    "\n",
    "print(\"Determinante (matriz triangular):\", determinante_triangular(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778dd97",
   "metadata": {},
   "source": [
    "# c) [0.5 puntos] Determ´ınese de forma justificada c´omo alteran el determinante de una\n",
    "# matriz n × n las dos operaciones elementales siguientes:\n",
    "# Intercambiar una fila (o columna) por otra fila (o columna).\n",
    "# Sumar a una fila (o columna) otra fila (o columna) multiplicada por un escalar α.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12532a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante original:         -3\n",
      "Después de intercambiar filas: 3\n",
      "Después de suma con escalar:  -3\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Determinante con definición recursiva (ya visto antes)\n",
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "    if n == 2:\n",
    "        return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += (-1)**j * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Matriz original\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "]\n",
    "\n",
    "# Intercambiar dos filas\n",
    "B = copy.deepcopy(A)\n",
    "B[0], B[1] = B[1], B[0]\n",
    "\n",
    "# Sumar a una fila otra multiplicada por un escalar\n",
    "C = copy.deepcopy(A)\n",
    "alpha = 2\n",
    "for j in range(len(C[0])):\n",
    "    C[1][j] += alpha * C[0][j]  # fila 2 = fila 2 + 2 * fila 1\n",
    "\n",
    "# Cálculo de determinantes\n",
    "det_A = determinante_recursivo(A)\n",
    "det_B = determinante_recursivo(B)\n",
    "det_C = determinante_recursivo(C)\n",
    "\n",
    "# Resultados\n",
    "print(\"Determinante original:        \", det_A)\n",
    "print(\"Después de intercambiar filas:\", det_B)  # debería ser -det_A\n",
    "print(\"Después de suma con escalar: \", det_C)  # debería ser igual a det_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5292b",
   "metadata": {},
   "source": [
    "# d) [1 punto] Investiga sobre el m´etodo de eliminaci´on de Gauss con pivoteo parcial e\n",
    "# implem´entalo para escalonar una matriz (es decir, convertirla en una matriz triangular\n",
    "# inferior) a partir de las operaciones elementales descritas en el apartado anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7725d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz escalonada (triangular superior):\n",
      "[-3, -1, 2]\n",
      "[0.0, 1.6666666666666665, 0.6666666666666667]\n",
      "[0.0, 0.0, 0.19999999999999987]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def escalonar_gauss_pivoteo(mat):\n",
    "    \"\"\"\n",
    "    Escalona una matriz cuadrada usando eliminación de Gauss con pivoteo parcial.\n",
    "    Convierte la matriz en triangular superior.\n",
    "    \"\"\"\n",
    "    A = copy.deepcopy(mat)\n",
    "    n = len(A)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Buscar fila con el valor absoluto más grande en la columna i\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            continue  # Si el pivote es 0, no se puede hacer nada\n",
    "\n",
    "        # Intercambiar filas\n",
    "        A[i], A[max_fila] = A[max_fila], A[i]\n",
    "\n",
    "        # Eliminar elementos debajo del pivote\n",
    "        for j in range(i + 1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "\n",
    "    return A\n",
    "\n",
    "# Ejemplo\n",
    "A = [\n",
    "    [2, 1, -1],\n",
    "    [-3, -1, 2],\n",
    "    [-2, 1, 2]\n",
    "]\n",
    "\n",
    "matriz_escalonada = escalonar_gauss_pivoteo(A)\n",
    "\n",
    "# 🔽 Mostrar el resultado\n",
    "print(\"Matriz escalonada (triangular superior):\")\n",
    "for fila in matriz_escalonada:\n",
    "    print(fila)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125211cb",
   "metadata": {},
   "source": [
    "# e) [0.5 puntos] ¿C´omo se podr´ıa calcular el determinante de una matriz haciendo beneficio\n",
    "# de la estrategia anterior y del efecto de aplicar las operaciones elementales pertinentes?\n",
    "# Implementa una nueva funci´on, determinante gauss, que calcule el determinante de\n",
    "# una matriz utilizando eliminaci´on gaussiana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74ad501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante (por Gauss): -0.9999999999999993\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def determinante_gauss(mat):\n",
    "    \"\"\"\n",
    "    Calcula el determinante de una matriz cuadrada usando eliminación de Gauss con pivoteo parcial.\n",
    "    \"\"\"\n",
    "    A = copy.deepcopy(mat)\n",
    "    n = len(A)\n",
    "    intercambio_signo = 1  # +1 si número par de intercambios, -1 si impar\n",
    "\n",
    "    for i in range(n):\n",
    "        # Pivoteo parcial: fila con mayor valor absoluto en la columna i\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            return 0  # Determinante es cero si hay ceros debajo del pivote\n",
    "\n",
    "        # Intercambiar filas si es necesario\n",
    "        if max_fila != i:\n",
    "            A[i], A[max_fila] = A[max_fila], A[i]\n",
    "            intercambio_signo *= -1  # Cambia el signo del determinante\n",
    "\n",
    "        # Eliminar elementos debajo del pivote\n",
    "        for j in range(i + 1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "\n",
    "    # Producto de la diagonal\n",
    "    producto_diag = 1\n",
    "    for i in range(n):\n",
    "        producto_diag *= A[i][i]\n",
    "\n",
    "    return intercambio_signo * producto_diag\n",
    "\n",
    "# 🔽 Ejemplo de uso:\n",
    "A = [\n",
    "    [2, 1, -1],\n",
    "    [-3, -1, 2],\n",
    "    [-2, 1, 2]\n",
    "]\n",
    "\n",
    "resultado = determinante_gauss(A)\n",
    "print(\"Determinante (por Gauss):\", resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceae346",
   "metadata": {},
   "source": [
    "# f ) [0.5 puntos] Obt´en la complejidad computacional asociada al c´alculo del determinante con la definici´on recursiva y con el m´etodo de eliminaci´on de Gauss con pivoteo parcial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e20ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n |   Recursivo (s) |  Gauss (s)\n",
      "-----------------------------------\n",
      " 2 |        0.000002 |   0.000009\n",
      " 3 |        0.000005 |   0.000006\n",
      " 4 |        0.000010 |   0.000006\n",
      " 5 |        0.000036 |   0.000007\n",
      " 6 |        0.000226 |   0.000010\n",
      " 7 |        0.001464 |   0.000015\n",
      " 8 |        0.012123 |   0.000027\n",
      " 9 |        0.106508 |   0.000028\n",
      "10 |        1.061676 |   0.000036\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Determinante recursivo (Laplace)\n",
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "    if n == 2:\n",
    "        return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += (-1)**j * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Determinante con eliminación de Gauss\n",
    "def determinante_gauss(mat):\n",
    "    A = [fila[:] for fila in mat]\n",
    "    n = len(A)\n",
    "    signo = 1\n",
    "    for i in range(n):\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            return 0\n",
    "        if max_fila != i:\n",
    "            A[i], A[max_fila] = A[max_fila], A[i]\n",
    "            signo *= -1\n",
    "        for j in range(i+1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "    det = signo\n",
    "    for i in range(n):\n",
    "        det *= A[i][i]\n",
    "    return det\n",
    "\n",
    "# Generador de matrices aleatorias con valores entre 0 y 1\n",
    "def generar_matriz(n):\n",
    "    return [[random.random() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "# Comparación de tiempos\n",
    "print(f\"{'n':>2} | {'Recursivo (s)':>15} | {'Gauss (s)':>10}\")\n",
    "print(\"-\"*35)\n",
    "\n",
    "for n in range(2, 11):\n",
    "    A = generar_matriz(n)\n",
    "\n",
    "    # Tiempo recursivo\n",
    "    inicio = time.time()\n",
    "    determinante_recursivo(A)\n",
    "    t_recursivo = time.time() - inicio\n",
    "\n",
    "    # Tiempo Gauss\n",
    "    inicio = time.time()\n",
    "    determinante_gauss(A)\n",
    "    t_gauss = time.time() - inicio\n",
    "\n",
    "    print(f\"{n:>2} | {t_recursivo:>15.6f} | {t_gauss:>10.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e4fcd-0578-4864-babc-82ef7821bf3d",
   "metadata": {},
   "source": [
    "# g) [1 punto] Utilizando numpy.random.rand, genera matrices cuadradas aleatorias de la\n",
    "# forma An ∈ R n×n, para 2 ≤ n ≤ 10, y confecciona una tabla comparativa del tiempo de\n",
    "# ejecuci´on asociado a cada una de las variantes siguientes, interpretando los resultados:\n",
    "# - Utilizando determinante recursivo.\n",
    "# - Empleando determinante gauss.\n",
    "# - Haciendo uso de la funci´on preprogramada numpy.linalg.det.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0c7826-9ab8-4119-9ce5-8bbf11508ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n  Recursivo (s)  Gauss (s)  NumPy (s)\n",
      "0   2       0.000008   0.000041   0.000033\n",
      "1   3       0.000548   0.000045   0.000021\n",
      "2   4       0.000802   0.000045   0.000020\n",
      "3   5       0.001062   0.000131   0.000036\n",
      "4   6       0.005847   0.000055   0.000029\n",
      "5   7       0.033449   0.000081   0.000042\n",
      "6   8       0.268274   0.000082   0.000030\n",
      "7   9       2.420373   0.000098   0.000061\n",
      "8  10      24.122509   0.000114   0.000034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# ========================\n",
    "# Método 1: Determinante recursivo\n",
    "# ========================\n",
    "def determinante_recursivo(A):\n",
    "    n = len(A)\n",
    "    if n == 1:\n",
    "        return A[0, 0]\n",
    "    if n == 2:\n",
    "        return A[0, 0]*A[1, 1] - A[0, 1]*A[1, 0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = np.delete(np.delete(A, 0, axis=0), j, axis=1)\n",
    "        det += (-1)**j * A[0, j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# ========================\n",
    "# Método 2: Eliminación de Gauss\n",
    "# ========================\n",
    "def determinante_gauss(A):\n",
    "    A = A.copy().astype(float)\n",
    "    n = len(A)\n",
    "    det = 1\n",
    "    for i in range(n):\n",
    "        if A[i, i] == 0:\n",
    "            for j in range(i+1, n):\n",
    "                if A[j, i] != 0:\n",
    "                    A[[i, j]] = A[[j, i]]\n",
    "                    det *= -1\n",
    "                    break\n",
    "        if A[i, i] == 0:\n",
    "            return 0\n",
    "        for j in range(i+1, n):\n",
    "            factor = A[j, i] / A[i, i]\n",
    "            A[j] -= factor * A[i]\n",
    "    for i in range(n):\n",
    "        det *= A[i, i]\n",
    "    return det\n",
    "\n",
    "# ========================\n",
    "# Comparación de tiempos\n",
    "# ========================\n",
    "resultados = []\n",
    "\n",
    "for n in range(2, 11):\n",
    "    A = np.random.rand(n, n)\n",
    "    \n",
    "    # Método 1: Recursivo\n",
    "    inicio = time.perf_counter()\n",
    "    determinante_recursivo(A)\n",
    "    tiempo_recursivo = time.perf_counter() - inicio\n",
    "    \n",
    "    # Método 2: Gauss\n",
    "    inicio = time.perf_counter()\n",
    "    determinante_gauss(A)\n",
    "    tiempo_gauss = time.perf_counter() - inicio\n",
    "    \n",
    "    # Método 3: NumPy\n",
    "    inicio = time.perf_counter()\n",
    "    np.linalg.det(A)\n",
    "    tiempo_numpy = time.perf_counter() - inicio\n",
    "    \n",
    "    resultados.append({\n",
    "        'n': n,\n",
    "        'Recursivo (s)': tiempo_recursivo,\n",
    "        'Gauss (s)': tiempo_gauss,\n",
    "        'NumPy (s)': tiempo_numpy\n",
    "    })\n",
    "\n",
    "# Mostrar tabla\n",
    "tabla = pd.DataFrame(resultados)\n",
    "print(tabla)  #  Esto imprime la tabla en consola\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac307a-8804-4689-8bef-a53f8e9c62f8",
   "metadata": {},
   "source": [
    "# 2. En este ejercicio trabajaremos con el m´etodo de descenso de gradiente, el cual constituye\n",
    "# otra herramienta crucial, en esta ocasi´on de la rama del c´alculo, para el proceso de retropropagaci´on asociado al entrenamiento de una red neuronal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e4277-4a4b-4eb9-b95b-a945a2ae416d",
   "metadata": {},
   "source": [
    "a) [1 punto] Progr´amese en Python el m´etodo de descenso de gradiente para funciones de n variables. La funci´on deber´a tener como par´ametros de entradas: \n",
    "- El gradiente de la funci´on que se desea minimizar ∇f (puede venir dada como otra funci´on previamente implementada, grad f, con entrada un vector, representando el punto donde se quiere calcular el gradiente, y salida otro vector, representando el gradiente de f en dicho punto).\n",
    "- Un valor inicial x0 ∈ R n (almacenado en un vector de n componentes).\n",
    "- El ratio de aprendizaje γ (que se asume constante para cada iteraci´on).\n",
    "- Un par´ametro de tolerancia tol (con el que finalizar el proceso cuando ∥∇f(x)∥2 <\n",
    "tol).\n",
    "- Un n´umero m´aximo de iteraciones maxit (con el fin de evitar ejecuciones indefinidas en caso de divergencia o convergencia muy lenta).\n",
    "- La salida de la funci´on deber´a ser la aproximaci´on del x que cumple f′(x) ≈ 0, correspondiente a la ´ultima iteraci´on realizada en el m´etodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8abbb3-5635-4653-9cbb-f2756756d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Convergencia alcanzada en 70 iteraciones.\n",
      "🔍 Aproximación al mínimo: [ 0.99999979 -1.99999959]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# =========================================\n",
    "# Función: Descenso de Gradiente\n",
    "# =========================================\n",
    "def descenso_gradiente(grad_f, x0, gamma, tol, maxit):\n",
    "    \"\"\"\n",
    "    Método de descenso de gradiente para minimizar funciones multivariables.\n",
    "\n",
    "    Parámetros:\n",
    "    - grad_f: función gradiente (entrada: np.array, salida: np.array)\n",
    "    - x0: vector inicial np.array([x1, x2, ..., xn])\n",
    "    - gamma: ratio de aprendizaje\n",
    "    - tol: tolerancia (criterio de parada)\n",
    "    - maxit: número máximo de iteraciones\n",
    "\n",
    "    Retorna:\n",
    "    - x: punto aproximado donde gradiente ≈ 0\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for i in range(maxit):\n",
    "        grad = grad_f(x)\n",
    "        norma_grad = np.linalg.norm(grad)\n",
    "        \n",
    "        if norma_grad < tol:\n",
    "            print(f\"✅ Convergencia alcanzada en {i+1} iteraciones.\")\n",
    "            return x\n",
    "        \n",
    "        x = x - gamma * grad  # paso hacia el mínimo\n",
    "\n",
    "    print(\"⚠️ Se alcanzó el número máximo de iteraciones sin converger.\")\n",
    "    return x\n",
    "\n",
    "# =========================================\n",
    "# Ejemplo: f(x, y) = (x - 1)^2 + (y + 2)^2\n",
    "# Gradiente: ∇f(x, y) = [2(x - 1), 2(y + 2)]\n",
    "# =========================================\n",
    "def gradiente_ejemplo(x):\n",
    "    return np.array([\n",
    "        2 * (x[0] - 1),\n",
    "        2 * (x[1] + 2)\n",
    "    ])\n",
    "\n",
    "# =========================================\n",
    "# Parámetros de entrada\n",
    "# =========================================\n",
    "x0 = np.array([0.0, 0.0])   # Punto inicial\n",
    "gamma = 0.1                 # Ratio de aprendizaje\n",
    "tol = 1e-6                  # Tolerancia\n",
    "maxit = 1000                # Máximo de iteraciones\n",
    "\n",
    "# =========================================\n",
    "# Ejecutar algoritmo\n",
    "# =========================================\n",
    "x_min = descenso_gradiente(gradiente_ejemplo, x0, gamma, tol, maxit)\n",
    "print(\"🔍 Aproximación al mínimo:\", x_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00a317-8ecf-4ea6-91c2-825265b0758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccd00cf-51aa-40e0-8e23-dee3da79873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergencia alcanzada en 832 iteraciones.\n",
      "x que minimiza f(x): 1.0000000000000275\n",
      "f(x_min): 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definición de la función y su derivada\n",
    "def f(x):\n",
    "    return 3*x**4 + 4*x**3 - 12*x**2 + 7\n",
    "\n",
    "def df(x):\n",
    "    return 12*x**3 + 12*x**2 - 24*x\n",
    "\n",
    "# Método de descenso de gradiente para funciones R → R\n",
    "def descenso_gradiente_1d(grad_f, x0, gamma, tol, maxit):\n",
    "    x = x0\n",
    "    for i in range(int(maxit)):\n",
    "        grad = grad_f(x)\n",
    "        if abs(grad) < tol:\n",
    "            print(f\"Convergencia alcanzada en {i+1} iteraciones.\")\n",
    "            return x\n",
    "        x = x - gamma * grad\n",
    "    print(\"Se alcanzó el número máximo de iteraciones sin convergencia.\")\n",
    "    return x\n",
    "\n",
    "# Parámetros del problema\n",
    "x0 = 3\n",
    "gamma = 0.001\n",
    "tol = 1e-12\n",
    "maxit = 1e5\n",
    "\n",
    "# Ejecutar el método\n",
    "x_min = descenso_gradiente_1d(df, x0, gamma, tol, maxit)\n",
    "print(\"x que minimiza f(x):\", x_min)\n",
    "print(\"f(x_min):\", f(x_min))\n"
   ]
  },
  {
   "attachments": {
    "f55259a9-76a5-4541-b6b2-665990dbaf33.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "98cec6dd-8a65-4a2d-8c4a-022259b8e0b4",
   "metadata": {},
   "source": [
    "![image.png](attachment:f55259a9-76a5-4541-b6b2-665990dbaf33.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a666ff-377c-4422-8a9b-d0c8aae98991",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '´' (U+00B4) (176085724.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    i [0.5 puntos] Aplica el m´etodo sobre f(x) con x0 = 3 γ = 0.001, tol=1e-12,\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '´' (U+00B4)\n"
     ]
    }
   ],
   "source": [
    "i [0.5 puntos] Aplica el m´etodo sobre f(x) con x0 = 3 γ = 0.001, tol=1e-12,\n",
    "maxit=1e5.\n",
    "en python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedcd56-9642-4785-95b0-b015a1787b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
