{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0d607f",
   "metadata": {},
   "source": [
    "# Ejercicios evaluables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6184e25",
   "metadata": {},
   "source": [
    "# 1. Tal y como ya hemos visto en clase, la variedad de herramientas proporcionadas por el\n",
    "Â´algebra lineal son cruciales para desarrollar y fundamentar las bases de una variedad de\n",
    "tÂ´ecnicas relacionadas con el aprendizaje automÂ´atico. Con ella, podemos describir el proceso\n",
    "de propagaciÂ´on hacia adelante en una red neuronal, identificar mÂ´Ä±nimos locales en funciones\n",
    "multivariables (crucial para el proceso de retropropagaciÂ´on) o la descripciÂ´on y empleo de\n",
    "mÂ´etodos de reducciÂ´on de la dimensionalidad, como el anÂ´alisis de componentes principales\n",
    "(PCA), entre muchas otras aplicaciones.\n",
    "Cuando trabajamos en la prÂ´actica dentro de este Â´ambito, la cantidad de datos que manejamos\n",
    "puede ser muy grande, por lo que es especialmente importante emplear algoritmos eficientes\n",
    "y optimizados para reducir el coste computacional en la medida de lo posible. Por todo ello,\n",
    "el objetivo de este ejercicio es el de ilustrar las diferentes alternativas que pueden existir\n",
    "para realizar un proceso relacionado con el Â´algebra lineal y el impacto que puede tener cada\n",
    "variante en tÂ´erminos del coste computacional del mismo. En este caso en particular, y a modo\n",
    "de ilustraciÂ´on, nos centraremos en el cÂ´alculo del determinante de una matriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570e410",
   "metadata": {},
   "source": [
    "# a) [1 punto] Implementa una funciÂ´on, determinante recursivo, que obtenga el determinante de una matriz cuadrada utilizando la definiciÂ´on recursiva de Laplace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7fc8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante: 1\n"
     ]
    }
   ],
   "source": [
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "\n",
    "    # Caso base 1x1\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "\n",
    "    # Caso base 2x2\n",
    "    if n == 2:\n",
    "        return mat[0][0] * mat[1][1] - mat[0][1] * mat[1][0]\n",
    "\n",
    "    # RecursiÃ³n para n > 2\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        # Crear el menor\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += ((-1) ** j) * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Ejemplo de uso\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [0, 1, 4],\n",
    "    [5, 6, 0]\n",
    "]\n",
    "\n",
    "print(\"Determinante:\", determinante_recursivo(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc9366",
   "metadata": {},
   "source": [
    "# b).  [0.5 puntos] Si A es una matriz cuadrada nÃ—n y triangular (superior o inferior, es decir,\n",
    "# con entradas nulas por debajo o por encima de la diagonal, respectivamente), Â¿existe\n",
    "# alguna forma de calcular de forma directa y sencilla su determinante? JustifÂ´Ä±quese la\n",
    "# respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930e1d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante (matriz triangular): 36\n"
     ]
    }
   ],
   "source": [
    "def determinante_triangular(mat):\n",
    "    \"\"\"\n",
    "    Calcula el determinante de una matriz triangular (superior o inferior).\n",
    "    Se asume que la matriz es cuadrada y triangular.\n",
    "    \"\"\"\n",
    "    n = len(mat)\n",
    "    det = 1\n",
    "    for i in range(n):\n",
    "        det *= mat[i][i]\n",
    "    return det\n",
    "\n",
    "# Ejemplo: matriz triangular superior\n",
    "A = [\n",
    "    [3, 5, 1],\n",
    "    [0, 2, 4],\n",
    "    [0, 0, 6]\n",
    "]\n",
    "\n",
    "print(\"Determinante (matriz triangular):\", determinante_triangular(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9778dd97",
   "metadata": {},
   "source": [
    "# c) [0.5 puntos] DetermÂ´Ä±nese de forma justificada cÂ´omo alteran el determinante de una\n",
    "# matriz n Ã— n las dos operaciones elementales siguientes:\n",
    "# Intercambiar una fila (o columna) por otra fila (o columna).\n",
    "# Sumar a una fila (o columna) otra fila (o columna) multiplicada por un escalar Î±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12532a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante original:         -3\n",
      "DespuÃ©s de intercambiar filas: 3\n",
      "DespuÃ©s de suma con escalar:  -3\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Determinante con definiciÃ³n recursiva (ya visto antes)\n",
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "    if n == 2:\n",
    "        return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += (-1)**j * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Matriz original\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 10]\n",
    "]\n",
    "\n",
    "# Intercambiar dos filas\n",
    "B = copy.deepcopy(A)\n",
    "B[0], B[1] = B[1], B[0]\n",
    "\n",
    "# Sumar a una fila otra multiplicada por un escalar\n",
    "C = copy.deepcopy(A)\n",
    "alpha = 2\n",
    "for j in range(len(C[0])):\n",
    "    C[1][j] += alpha * C[0][j]  # fila 2 = fila 2 + 2 * fila 1\n",
    "\n",
    "# CÃ¡lculo de determinantes\n",
    "det_A = determinante_recursivo(A)\n",
    "det_B = determinante_recursivo(B)\n",
    "det_C = determinante_recursivo(C)\n",
    "\n",
    "# Resultados\n",
    "print(\"Determinante original:        \", det_A)\n",
    "print(\"DespuÃ©s de intercambiar filas:\", det_B)  # deberÃ­a ser -det_A\n",
    "print(\"DespuÃ©s de suma con escalar: \", det_C)  # deberÃ­a ser igual a det_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5292b",
   "metadata": {},
   "source": [
    "# d) [1 punto] Investiga sobre el mÂ´etodo de eliminaciÂ´on de Gauss con pivoteo parcial e\n",
    "# implemÂ´entalo para escalonar una matriz (es decir, convertirla en una matriz triangular\n",
    "# inferior) a partir de las operaciones elementales descritas en el apartado anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7725d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz escalonada (triangular superior):\n",
      "[-3, -1, 2]\n",
      "[0.0, 1.6666666666666665, 0.6666666666666667]\n",
      "[0.0, 0.0, 0.19999999999999987]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def escalonar_gauss_pivoteo(mat):\n",
    "    \"\"\"\n",
    "    Escalona una matriz cuadrada usando eliminaciÃ³n de Gauss con pivoteo parcial.\n",
    "    Convierte la matriz en triangular superior.\n",
    "    \"\"\"\n",
    "    A = copy.deepcopy(mat)\n",
    "    n = len(A)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Buscar fila con el valor absoluto mÃ¡s grande en la columna i\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            continue  # Si el pivote es 0, no se puede hacer nada\n",
    "\n",
    "        # Intercambiar filas\n",
    "        A[i], A[max_fila] = A[max_fila], A[i]\n",
    "\n",
    "        # Eliminar elementos debajo del pivote\n",
    "        for j in range(i + 1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "\n",
    "    return A\n",
    "\n",
    "# Ejemplo\n",
    "A = [\n",
    "    [2, 1, -1],\n",
    "    [-3, -1, 2],\n",
    "    [-2, 1, 2]\n",
    "]\n",
    "\n",
    "matriz_escalonada = escalonar_gauss_pivoteo(A)\n",
    "\n",
    "# ðŸ”½ Mostrar el resultado\n",
    "print(\"Matriz escalonada (triangular superior):\")\n",
    "for fila in matriz_escalonada:\n",
    "    print(fila)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125211cb",
   "metadata": {},
   "source": [
    "# e) [0.5 puntos] Â¿CÂ´omo se podrÂ´Ä±a calcular el determinante de una matriz haciendo beneficio\n",
    "# de la estrategia anterior y del efecto de aplicar las operaciones elementales pertinentes?\n",
    "# Implementa una nueva funciÂ´on, determinante gauss, que calcule el determinante de\n",
    "# una matriz utilizando eliminaciÂ´on gaussiana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74ad501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinante (por Gauss): -0.9999999999999993\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def determinante_gauss(mat):\n",
    "    \"\"\"\n",
    "    Calcula el determinante de una matriz cuadrada usando eliminaciÃ³n de Gauss con pivoteo parcial.\n",
    "    \"\"\"\n",
    "    A = copy.deepcopy(mat)\n",
    "    n = len(A)\n",
    "    intercambio_signo = 1  # +1 si nÃºmero par de intercambios, -1 si impar\n",
    "\n",
    "    for i in range(n):\n",
    "        # Pivoteo parcial: fila con mayor valor absoluto en la columna i\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            return 0  # Determinante es cero si hay ceros debajo del pivote\n",
    "\n",
    "        # Intercambiar filas si es necesario\n",
    "        if max_fila != i:\n",
    "            A[i], A[max_fila] = A[max_fila], A[i]\n",
    "            intercambio_signo *= -1  # Cambia el signo del determinante\n",
    "\n",
    "        # Eliminar elementos debajo del pivote\n",
    "        for j in range(i + 1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "\n",
    "    # Producto de la diagonal\n",
    "    producto_diag = 1\n",
    "    for i in range(n):\n",
    "        producto_diag *= A[i][i]\n",
    "\n",
    "    return intercambio_signo * producto_diag\n",
    "\n",
    "# ðŸ”½ Ejemplo de uso:\n",
    "A = [\n",
    "    [2, 1, -1],\n",
    "    [-3, -1, 2],\n",
    "    [-2, 1, 2]\n",
    "]\n",
    "\n",
    "resultado = determinante_gauss(A)\n",
    "print(\"Determinante (por Gauss):\", resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceae346",
   "metadata": {},
   "source": [
    "# f ) [0.5 puntos] ObtÂ´en la complejidad computacional asociada al cÂ´alculo del determinante con la definiciÂ´on recursiva y con el mÂ´etodo de eliminaciÂ´on de Gauss con pivoteo parcial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e20ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n |   Recursivo (s) |  Gauss (s)\n",
      "-----------------------------------\n",
      " 2 |        0.000002 |   0.000009\n",
      " 3 |        0.000005 |   0.000006\n",
      " 4 |        0.000010 |   0.000006\n",
      " 5 |        0.000036 |   0.000007\n",
      " 6 |        0.000226 |   0.000010\n",
      " 7 |        0.001464 |   0.000015\n",
      " 8 |        0.012123 |   0.000027\n",
      " 9 |        0.106508 |   0.000028\n",
      "10 |        1.061676 |   0.000036\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Determinante recursivo (Laplace)\n",
    "def determinante_recursivo(mat):\n",
    "    n = len(mat)\n",
    "    if n == 1:\n",
    "        return mat[0][0]\n",
    "    if n == 2:\n",
    "        return mat[0][0]*mat[1][1] - mat[0][1]*mat[1][0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = [fila[:j] + fila[j+1:] for fila in mat[1:]]\n",
    "        det += (-1)**j * mat[0][j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# Determinante con eliminaciÃ³n de Gauss\n",
    "def determinante_gauss(mat):\n",
    "    A = [fila[:] for fila in mat]\n",
    "    n = len(A)\n",
    "    signo = 1\n",
    "    for i in range(n):\n",
    "        max_fila = max(range(i, n), key=lambda k: abs(A[k][i]))\n",
    "        if A[max_fila][i] == 0:\n",
    "            return 0\n",
    "        if max_fila != i:\n",
    "            A[i], A[max_fila] = A[max_fila], A[i]\n",
    "            signo *= -1\n",
    "        for j in range(i+1, n):\n",
    "            factor = A[j][i] / A[i][i]\n",
    "            for k in range(i, n):\n",
    "                A[j][k] -= factor * A[i][k]\n",
    "    det = signo\n",
    "    for i in range(n):\n",
    "        det *= A[i][i]\n",
    "    return det\n",
    "\n",
    "# Generador de matrices aleatorias con valores entre 0 y 1\n",
    "def generar_matriz(n):\n",
    "    return [[random.random() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "# ComparaciÃ³n de tiempos\n",
    "print(f\"{'n':>2} | {'Recursivo (s)':>15} | {'Gauss (s)':>10}\")\n",
    "print(\"-\"*35)\n",
    "\n",
    "for n in range(2, 11):\n",
    "    A = generar_matriz(n)\n",
    "\n",
    "    # Tiempo recursivo\n",
    "    inicio = time.time()\n",
    "    determinante_recursivo(A)\n",
    "    t_recursivo = time.time() - inicio\n",
    "\n",
    "    # Tiempo Gauss\n",
    "    inicio = time.time()\n",
    "    determinante_gauss(A)\n",
    "    t_gauss = time.time() - inicio\n",
    "\n",
    "    print(f\"{n:>2} | {t_recursivo:>15.6f} | {t_gauss:>10.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e4fcd-0578-4864-babc-82ef7821bf3d",
   "metadata": {},
   "source": [
    "# g) [1 punto] Utilizando numpy.random.rand, genera matrices cuadradas aleatorias de la\n",
    "# forma An âˆˆ R nÃ—n, para 2 â‰¤ n â‰¤ 10, y confecciona una tabla comparativa del tiempo de\n",
    "# ejecuciÂ´on asociado a cada una de las variantes siguientes, interpretando los resultados:\n",
    "# - Utilizando determinante recursivo.\n",
    "# - Empleando determinante gauss.\n",
    "# - Haciendo uso de la funciÂ´on preprogramada numpy.linalg.det.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0c7826-9ab8-4119-9ce5-8bbf11508ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n  Recursivo (s)  Gauss (s)  NumPy (s)\n",
      "0   2       0.000008   0.000041   0.000033\n",
      "1   3       0.000548   0.000045   0.000021\n",
      "2   4       0.000802   0.000045   0.000020\n",
      "3   5       0.001062   0.000131   0.000036\n",
      "4   6       0.005847   0.000055   0.000029\n",
      "5   7       0.033449   0.000081   0.000042\n",
      "6   8       0.268274   0.000082   0.000030\n",
      "7   9       2.420373   0.000098   0.000061\n",
      "8  10      24.122509   0.000114   0.000034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# ========================\n",
    "# MÃ©todo 1: Determinante recursivo\n",
    "# ========================\n",
    "def determinante_recursivo(A):\n",
    "    n = len(A)\n",
    "    if n == 1:\n",
    "        return A[0, 0]\n",
    "    if n == 2:\n",
    "        return A[0, 0]*A[1, 1] - A[0, 1]*A[1, 0]\n",
    "    det = 0\n",
    "    for j in range(n):\n",
    "        menor = np.delete(np.delete(A, 0, axis=0), j, axis=1)\n",
    "        det += (-1)**j * A[0, j] * determinante_recursivo(menor)\n",
    "    return det\n",
    "\n",
    "# ========================\n",
    "# MÃ©todo 2: EliminaciÃ³n de Gauss\n",
    "# ========================\n",
    "def determinante_gauss(A):\n",
    "    A = A.copy().astype(float)\n",
    "    n = len(A)\n",
    "    det = 1\n",
    "    for i in range(n):\n",
    "        if A[i, i] == 0:\n",
    "            for j in range(i+1, n):\n",
    "                if A[j, i] != 0:\n",
    "                    A[[i, j]] = A[[j, i]]\n",
    "                    det *= -1\n",
    "                    break\n",
    "        if A[i, i] == 0:\n",
    "            return 0\n",
    "        for j in range(i+1, n):\n",
    "            factor = A[j, i] / A[i, i]\n",
    "            A[j] -= factor * A[i]\n",
    "    for i in range(n):\n",
    "        det *= A[i, i]\n",
    "    return det\n",
    "\n",
    "# ========================\n",
    "# ComparaciÃ³n de tiempos\n",
    "# ========================\n",
    "resultados = []\n",
    "\n",
    "for n in range(2, 11):\n",
    "    A = np.random.rand(n, n)\n",
    "    \n",
    "    # MÃ©todo 1: Recursivo\n",
    "    inicio = time.perf_counter()\n",
    "    determinante_recursivo(A)\n",
    "    tiempo_recursivo = time.perf_counter() - inicio\n",
    "    \n",
    "    # MÃ©todo 2: Gauss\n",
    "    inicio = time.perf_counter()\n",
    "    determinante_gauss(A)\n",
    "    tiempo_gauss = time.perf_counter() - inicio\n",
    "    \n",
    "    # MÃ©todo 3: NumPy\n",
    "    inicio = time.perf_counter()\n",
    "    np.linalg.det(A)\n",
    "    tiempo_numpy = time.perf_counter() - inicio\n",
    "    \n",
    "    resultados.append({\n",
    "        'n': n,\n",
    "        'Recursivo (s)': tiempo_recursivo,\n",
    "        'Gauss (s)': tiempo_gauss,\n",
    "        'NumPy (s)': tiempo_numpy\n",
    "    })\n",
    "\n",
    "# Mostrar tabla\n",
    "tabla = pd.DataFrame(resultados)\n",
    "print(tabla)  #  Esto imprime la tabla en consola\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac307a-8804-4689-8bef-a53f8e9c62f8",
   "metadata": {},
   "source": [
    "# 2. En este ejercicio trabajaremos con el mÂ´etodo de descenso de gradiente, el cual constituye\n",
    "# otra herramienta crucial, en esta ocasiÂ´on de la rama del cÂ´alculo, para el proceso de retropropagaciÂ´on asociado al entrenamiento de una red neuronal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e4277-4a4b-4eb9-b95b-a945a2ae416d",
   "metadata": {},
   "source": [
    "a) [1 punto] ProgrÂ´amese en Python el mÂ´etodo de descenso de gradiente para funciones de n variables. La funciÂ´on deberÂ´a tener como parÂ´ametros de entradas: \n",
    "- El gradiente de la funciÂ´on que se desea minimizar âˆ‡f (puede venir dada como otra funciÂ´on previamente implementada, grad f, con entrada un vector, representando el punto donde se quiere calcular el gradiente, y salida otro vector, representando el gradiente de f en dicho punto).\n",
    "- Un valor inicial x0 âˆˆ R n (almacenado en un vector de n componentes).\n",
    "- El ratio de aprendizaje Î³ (que se asume constante para cada iteraciÂ´on).\n",
    "- Un parÂ´ametro de tolerancia tol (con el que finalizar el proceso cuando âˆ¥âˆ‡f(x)âˆ¥2 <\n",
    "tol).\n",
    "- Un nÂ´umero mÂ´aximo de iteraciones maxit (con el fin de evitar ejecuciones indefinidas en caso de divergencia o convergencia muy lenta).\n",
    "- La salida de la funciÂ´on deberÂ´a ser la aproximaciÂ´on del x que cumple fâ€²(x) â‰ˆ 0, correspondiente a la Â´ultima iteraciÂ´on realizada en el mÂ´etodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8abbb3-5635-4653-9cbb-f2756756d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Convergencia alcanzada en 70 iteraciones.\n",
      "ðŸ” AproximaciÃ³n al mÃ­nimo: [ 0.99999979 -1.99999959]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# =========================================\n",
    "# FunciÃ³n: Descenso de Gradiente\n",
    "# =========================================\n",
    "def descenso_gradiente(grad_f, x0, gamma, tol, maxit):\n",
    "    \"\"\"\n",
    "    MÃ©todo de descenso de gradiente para minimizar funciones multivariables.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "    - grad_f: funciÃ³n gradiente (entrada: np.array, salida: np.array)\n",
    "    - x0: vector inicial np.array([x1, x2, ..., xn])\n",
    "    - gamma: ratio de aprendizaje\n",
    "    - tol: tolerancia (criterio de parada)\n",
    "    - maxit: nÃºmero mÃ¡ximo de iteraciones\n",
    "\n",
    "    Retorna:\n",
    "    - x: punto aproximado donde gradiente â‰ˆ 0\n",
    "    \"\"\"\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for i in range(maxit):\n",
    "        grad = grad_f(x)\n",
    "        norma_grad = np.linalg.norm(grad)\n",
    "        \n",
    "        if norma_grad < tol:\n",
    "            print(f\"âœ… Convergencia alcanzada en {i+1} iteraciones.\")\n",
    "            return x\n",
    "        \n",
    "        x = x - gamma * grad  # paso hacia el mÃ­nimo\n",
    "\n",
    "    print(\"âš ï¸ Se alcanzÃ³ el nÃºmero mÃ¡ximo de iteraciones sin converger.\")\n",
    "    return x\n",
    "\n",
    "# =========================================\n",
    "# Ejemplo: f(x, y) = (x - 1)^2 + (y + 2)^2\n",
    "# Gradiente: âˆ‡f(x, y) = [2(x - 1), 2(y + 2)]\n",
    "# =========================================\n",
    "def gradiente_ejemplo(x):\n",
    "    return np.array([\n",
    "        2 * (x[0] - 1),\n",
    "        2 * (x[1] + 2)\n",
    "    ])\n",
    "\n",
    "# =========================================\n",
    "# ParÃ¡metros de entrada\n",
    "# =========================================\n",
    "x0 = np.array([0.0, 0.0])   # Punto inicial\n",
    "gamma = 0.1                 # Ratio de aprendizaje\n",
    "tol = 1e-6                  # Tolerancia\n",
    "maxit = 1000                # MÃ¡ximo de iteraciones\n",
    "\n",
    "# =========================================\n",
    "# Ejecutar algoritmo\n",
    "# =========================================\n",
    "x_min = descenso_gradiente(gradiente_ejemplo, x0, gamma, tol, maxit)\n",
    "print(\"ðŸ” AproximaciÃ³n al mÃ­nimo:\", x_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00a317-8ecf-4ea6-91c2-825265b0758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccd00cf-51aa-40e0-8e23-dee3da79873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergencia alcanzada en 832 iteraciones.\n",
      "x que minimiza f(x): 1.0000000000000275\n",
      "f(x_min): 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# DefiniciÃ³n de la funciÃ³n y su derivada\n",
    "def f(x):\n",
    "    return 3*x**4 + 4*x**3 - 12*x**2 + 7\n",
    "\n",
    "def df(x):\n",
    "    return 12*x**3 + 12*x**2 - 24*x\n",
    "\n",
    "# MÃ©todo de descenso de gradiente para funciones R â†’ R\n",
    "def descenso_gradiente_1d(grad_f, x0, gamma, tol, maxit):\n",
    "    x = x0\n",
    "    for i in range(int(maxit)):\n",
    "        grad = grad_f(x)\n",
    "        if abs(grad) < tol:\n",
    "            print(f\"Convergencia alcanzada en {i+1} iteraciones.\")\n",
    "            return x\n",
    "        x = x - gamma * grad\n",
    "    print(\"Se alcanzÃ³ el nÃºmero mÃ¡ximo de iteraciones sin convergencia.\")\n",
    "    return x\n",
    "\n",
    "# ParÃ¡metros del problema\n",
    "x0 = 3\n",
    "gamma = 0.001\n",
    "tol = 1e-12\n",
    "maxit = 1e5\n",
    "\n",
    "# Ejecutar el mÃ©todo\n",
    "x_min = descenso_gradiente_1d(df, x0, gamma, tol, maxit)\n",
    "print(\"x que minimiza f(x):\", x_min)\n",
    "print(\"f(x_min):\", f(x_min))\n"
   ]
  },
  {
   "attachments": {
    "f55259a9-76a5-4541-b6b2-665990dbaf33.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "98cec6dd-8a65-4a2d-8c4a-022259b8e0b4",
   "metadata": {},
   "source": [
    "![image.png](attachment:f55259a9-76a5-4541-b6b2-665990dbaf33.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a666ff-377c-4422-8a9b-d0c8aae98991",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'Â´' (U+00B4) (176085724.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    i [0.5 puntos] Aplica el mÂ´etodo sobre f(x) con x0 = 3 Î³ = 0.001, tol=1e-12,\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character 'Â´' (U+00B4)\n"
     ]
    }
   ],
   "source": [
    "i [0.5 puntos] Aplica el mÂ´etodo sobre f(x) con x0 = 3 Î³ = 0.001, tol=1e-12,\n",
    "maxit=1e5.\n",
    "en python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedcd56-9642-4785-95b0-b015a1787b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
